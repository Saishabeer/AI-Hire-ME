<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>{{ interview.title }} - AI Voice Interview</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif; margin: 0; padding: 24px; color: #0b1220; }
    .container { max-width: 900px; margin: 0 auto; }
    h1 { margin: 0 0 8px; }
    .sub { color: #475569; margin: 0 0 20px; }
    .panel { background: #f8fafc; border: 1px solid #e2e8f0; border-radius: 12px; padding: 16px; margin-bottom: 16px; }
    .controls { display: flex; gap: 10px; align-items: center; }
    button { padding: 10px 14px; border: none; border-radius: 10px; font-weight: 600; cursor: pointer; }
    #start-interview { background: #38bdf8; color: #042029; }
    #end-interview { background: #f43f5e; color: #fff; }
    .status { display: flex; gap: 14px; color: #334155; font-size: 14px; }
    .hint { color: #475569; font-size: 14px; }
    pre { background: #0b1220; color: #cbd5e1; padding: 10px; border-radius: 10px; overflow: auto; max-height: 180px; }
    audio { display: none; }
  </style>
</head>
<body>
  <div class="container">
    <h1>{{ interview.title }}</h1>
    <p class="sub">The AI will ask only the questions you configured, in order, without asking you to start/stop recording.</p>

    <div class="panel">
      <div class="controls">
        <button id="start-interview">Start interview</button>
        <button id="end-interview">End interview</button>
        <div class="status">
          <span>Mic: <strong id="mic-state">off</strong></span>
          <span>Connection: <strong id="conn-state">idle</strong></span>
          <span>AI Audio: <strong id="ai-state">idle</strong></span>
        </div>
      </div>
      <p class="hint">Tip: Your browser may require one click to allow the microphone. After that, the session stays live until you end it.</p>
    </div>

    <div class="panel">
      <strong>Logs</strong>
      <pre id="logs"></pre>
    </div>

    <audio id="ai-remote-audio" autoplay playsinline></audio>
  </div>

  <script>
    (function () {
      let pc = null;
      let dc = null;
      let localStream = null;
      let remoteStream = null;
      let modelInUse = null;

      const micStateEl = document.getElementById("mic-state");
      const connStateEl = document.getElementById("conn-state");
      const aiStateEl = document.getElementById("ai-state");
      const logsEl = document.getElementById("logs");

      function log(line, obj) {
        const t = new Date().toISOString();
        logsEl.textContent += "[" + t + "] " + line + (obj ? " " + JSON.stringify(obj) : "") + "\n";
        logsEl.scrollTop = logsEl.scrollHeight;
      }

      async function createSession() {
        const resp = await fetch("{% url 'interviews:ai_interview_realtime_session' %}", {
          method: "POST",
          headers: {
            // CSRF is exempted server-side for this endpoint to simplify integration
            "Content-Type": "application/json"
          },
          // Send the interview id so the server can constrain the questions
          body: JSON.stringify({ interview_id: {{ interview.id }} })
        });
        if (!resp.ok) {
          const t = await resp.text();
          throw new Error("Failed to create realtime session: " + t);
        }
        return resp.json();
      }

      async function startRealtimeInterview() {
        try {
          document.getElementById("start-interview").disabled = true;
          connStateEl.textContent = "creating-session";
          const session = await createSession();
          const ephemeralKey = session.client_secret?.value || session.client_secret;
          modelInUse = session.model || "gpt-4o-realtime-preview-2024-12-17";
          log("Ephemeral session created", { model: modelInUse });

          // Get mic once
          localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
          micStateEl.textContent = "on";

          // Peer connection
          pc = new RTCPeerConnection({ iceServers: [{ urls: ["stun:stun.l.google.com:19302"] }] });
          pc.onconnectionstatechange = () => {
            connStateEl.textContent = pc.connectionState;
            log("RTCPeerConnection state", { state: pc.connectionState });
          };

          // Remote audio
          remoteStream = new MediaStream();
          const audioEl = document.getElementById("ai-remote-audio") || (function () {
            const a = document.createElement("audio");
            a.id = "ai-remote-audio";
            a.autoplay = true;
            a.playsInline = true;
            a.style.display = "none";
            document.body.appendChild(a);
            return a;
          })();
          audioEl.srcObject = remoteStream;

          pc.ontrack = (e) => {
            aiStateEl.textContent = "speaking";
            remoteStream.addTrack(e.track);
            e.track.onended = () => { aiStateEl.textContent = "idle"; };
          };

          // Attach local mic
          localStream.getTracks().forEach((t) => pc.addTrack(t, localStream));

          // Data channel for control events
          dc = pc.createDataChannel("oai-events");
          dc.onopen = () => {
            log("Data channel open.");
            // Start now; the strict question list is already in the session instructions
            const startEvent = {
              type: "response.create",
              response: {
                instructions: "Start the interview now with question 1.",
                modalities: ["text", "audio"]
              }
            };
            dc.send(JSON.stringify(startEvent));
          };
          dc.onmessage = (ev) => {
            try {
              const msg = JSON.parse(ev.data);
              log("Event from model", msg);
            } catch {
              log("Non-JSON message from model", { data: ev.data });
            }
          };
          dc.onclose = () => log("Data channel closed.");

          // SDP offer/answer with OpenAI Realtime
          const offer = await pc.createOffer({ offerToReceiveAudio: true, offerToReceiveVideo: false });
          await pc.setLocalDescription(offer);

          const sdpResp = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(modelInUse)}`, {
            method: "POST",
            body: offer.sdp,
            headers: {
              Authorization: `Bearer ${ephemeralKey}`,
              "Content-Type": "application/sdp"
            }
          });
          if (!sdpResp.ok) throw new Error(await sdpResp.text());
          const answer = await sdpResp.text();
          await pc.setRemoteDescription({ type: "answer", sdp: answer });

          window.__aiInterviewEnd__ = endRealtimeInterview; // expose an end handle if you want a button to call it
          connStateEl.textContent = "connected";
          log("Interview connected.");
        } catch (e) {
          console.error("Realtime interview failed to start:", e);
          alert("Failed to start interview: " + e.message);
          document.getElementById("start-interview").disabled = false;
          connStateEl.textContent = "error";
          log("Error", { error: e.message });
        }
      }

      function endRealtimeInterview() {
        try {
          if (dc && dc.readyState === "open") dc.close();
        } catch {}
        try {
          if (pc) pc.close();
        } catch {}
        try {
          if (localStream) localStream.getTracks().forEach((t) => t.stop());
        } catch {}
        pc = null;
        dc = null;
        localStream = null;
        remoteStream = null;
        micStateEl.textContent = "off";
        aiStateEl.textContent = "idle";
        connStateEl.textContent = "closed";
        document.getElementById("start-interview").disabled = false;
        log("Interview ended.");
      }

      // Wire up buttons and attempt auto-start (browsers may require a gesture)
      document.addEventListener("DOMContentLoaded", () => {
        const btn = document.getElementById("start-interview");
        const endBtn = document.getElementById("end-interview");
        if (btn) btn.addEventListener("click", startRealtimeInterview, { once: true });
        if (endBtn) endBtn.addEventListener("click", endRealtimeInterview);

        // Attempt autoplay start; if permissions block, fall back to button
        startRealtimeInterview().catch(() => {
          log("Autostart blocked by browser; waiting for user gesture.");
        });
      });
    })();
  </script>
</body>
</html>